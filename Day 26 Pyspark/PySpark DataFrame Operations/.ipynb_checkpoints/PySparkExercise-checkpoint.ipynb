{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "520b8c2d-ac0c-4987-a73b-f9d2c8b9cd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/09 17:59:03 WARN Utils: Your hostname, MaheshPC resolves to a loopback address: 127.0.1.1; using 192.168.1.7 instead (on interface enp5s0)\n",
      "24/01/09 17:59:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/09 17:59:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/01/09 17:59:04 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/01/09 17:59:04 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/01/09 17:59:04 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "24/01/09 17:59:04 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "24/01/09 17:59:04 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "24/01/09 17:59:04 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "24/01/09 17:59:04 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark is Connected\n"
     ]
    }
   ],
   "source": [
    "# Start a simple Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('exercise').getOrCreate()\n",
    "print('Spark is Connected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73f4792d-3509-4a12-8fa3-d3d8989462cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
      "|      Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
      "|2012-01-03|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996|\n",
      "|2012-01-04|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475|\n",
      "|2012-01-05|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|\n",
      "|2012-01-06|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922|\n",
      "|2012-01-09|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|\n",
      "|2012-01-10|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109|\n",
      "|2012-01-11|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098|\n",
      "|2012-01-12|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994|\n",
      "|2012-01-13|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996|\n",
      "|2012-01-17|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581|\n",
      "|2012-01-18|59.790001000000004|         60.029999|         59.650002|60.009997999999996| 5911400|         52.340131|\n",
      "|2012-01-19|             59.93|             60.73|             59.75|60.610001000000004| 9234600|         52.863447|\n",
      "|2012-01-20|             60.75|             61.25|         60.669998|61.009997999999996|10378800|53.212320999999996|\n",
      "|2012-01-23|         60.810001|             60.98|60.509997999999996|             60.91| 7134100|         53.125104|\n",
      "|2012-01-24|             60.75|              62.0|             60.75|61.389998999999996| 7362800| 53.54375400000001|\n",
      "|2012-01-25|             61.18|61.610001000000004|61.040001000000004|         61.470001| 5915800| 53.61353100000001|\n",
      "|2012-01-26|         61.799999|             61.84|             60.77|         60.970001| 7436200|         53.177436|\n",
      "|2012-01-27|60.860001000000004|         61.119999|60.540001000000004|60.709998999999996| 6287300|         52.950665|\n",
      "|2012-01-30|         60.470001|             61.32|         60.349998|         61.299999| 7636900|53.465256999999994|\n",
      "|2012-01-31|         61.529999|             61.57|         60.580002|61.360001000000004| 9761500|53.517590000000006|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load walmart dataset\n",
    "df = spark.read.csv('DatasetExercise/walmart_stock.csv',inferSchema=True,header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1845635b-e189-4040-b243-e6205e91af4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the column names\n",
    "# schema\n",
    "\n",
    "df.printSchema()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "257fabf1-8c5a-4cc2-8566-abbbecf24a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Date=datetime.date(2012, 1, 3), Open=59.970001, High=61.060001, Low=59.869999, Close=60.330002, Volume=12668800, Adj Close=52.619234999999996)\n",
      "Row(Date=datetime.date(2012, 1, 4), Open=60.209998999999996, High=60.349998, Low=59.470001, Close=59.709998999999996, Volume=9593300, Adj Close=52.078475)\n",
      "Row(Date=datetime.date(2012, 1, 5), Open=59.349998, High=59.619999, Low=58.369999, Close=59.419998, Volume=12768200, Adj Close=51.825539)\n",
      "Row(Date=datetime.date(2012, 1, 6), Open=59.419998, High=59.450001, Low=58.869999, Close=59.0, Volume=8069400, Adj Close=51.45922)\n",
      "Row(Date=datetime.date(2012, 1, 9), Open=59.029999, High=59.549999, Low=58.919998, Close=59.18, Volume=6679300, Adj Close=51.616215000000004)\n"
     ]
    }
   ],
   "source": [
    "# first 5 columns\n",
    "for i in df.head(5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1d851c6-491e-4914-9201-d24895d58048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/09 18:04:36 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|summary|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|  count|              1258|             1258|             1258|             1258|             1258|             1258|\n",
      "|   mean| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
      "| stddev|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
      "|    min|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
      "|    max|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# describe\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca6187fc-e073-4011-963d-58ebf60123a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------+--------+\n",
      "|summary|    OPEN|   Close|    HIGH|     LOW|\n",
      "+-------+--------+--------+--------+--------+\n",
      "|  count|1,258.00|1,258.00|1,258.00|1,258.00|\n",
      "|   mean|   72.36|   72.39|   72.84|   71.92|\n",
      "| stddev|    6.77|    6.76|    6.77|    6.74|\n",
      "|    min|   56.39|   56.42|   57.06|   56.30|\n",
      "|    max|   90.80|   90.47|   90.97|   89.25|\n",
      "+-------+--------+--------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to print decimal using format number\n",
    "from pyspark.sql.functions import format_number\n",
    "res = df.describe()\n",
    "res.select(res['summary'],format_number(res['Open'].cast('float'),2).alias('OPEN'),\n",
    "           format_number(res['Close'].cast('float'),2).alias('Close'),\n",
    "           format_number(res['High'].cast('float'),2).alias('HIGH'),\n",
    "           format_number(res['Low'].cast('float'),2).alias('LOW')\n",
    "         \n",
    "          \n",
    "          ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9ad8549-111f-4a85-9dff-59199ffb035f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            HV RATIO|\n",
      "+--------------------+\n",
      "|4.819714653321546E-6|\n",
      "|6.290848613094555E-6|\n",
      "|4.669412994783916E-6|\n",
      "|7.367338463826307E-6|\n",
      "|8.915604778943901E-6|\n",
      "|8.644477436914568E-6|\n",
      "|9.351828421515645E-6|\n",
      "| 8.29141562102703E-6|\n",
      "|7.712212102001476E-6|\n",
      "|7.071764823529412E-6|\n",
      "|1.015495466386981E-5|\n",
      "|6.576354146362592...|\n",
      "| 5.90145296180676E-6|\n",
      "|8.547679455011844E-6|\n",
      "|8.420709512685392E-6|\n",
      "|1.041448341728929...|\n",
      "|8.316075414862431E-6|\n",
      "|9.721183814992126E-6|\n",
      "|8.029436027707578E-6|\n",
      "|6.307432259386365E-6|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create new dataframe and make it HV ratio\n",
    "\n",
    "df2 = df.withColumn(\"HV RATIO\",df['High']/df['Volume'])\n",
    "df2.select('HV RATIO').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "302610d1-4b7f-43bc-b692-c020883f9a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2015, 1, 13)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# highest price\n",
    "df.orderBy(df [ 'High'].desc()) .head (1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac18467f-9de0-431d-ac91-72222ff776be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(Close)|\n",
      "+-----------------+\n",
      "|72.38844998012726|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "df.select (mean (\"Close\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8f13f2f-214d-4f76-9d84-3bce134711e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.141494435612083"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"What percentage of the time was the High greater than 80 dollars ?\n",
    "(Number of Days High>80)/(Total Days in the dataset)\"\"\"\n",
    "\n",
    "(df.filter (df[ 'High' ]>80) .count()*1.0 / df.count() )* 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fb5bff6-b48e-4119-b778-0786f4804a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "| corr(High, Volume)|\n",
      "+-------------------+\n",
      "|-0.3384326061737161|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pearson correlation\n",
    "from pyspark.sql.functions import corr\n",
    "df.select (corr('High','Volume')) .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78270d88-be50-4893-8bea-d529045cb1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
