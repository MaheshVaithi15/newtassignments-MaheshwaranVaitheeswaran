{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "44b00724-2d19-45ae-b6e9-f7b50a12e1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark is Connected\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('nlp1').getOrCreate()\n",
    "print('Spark is Connected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "be725f7e-d9b9-4695-968d-a4f177e68bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools for nlp as follows\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer,RegexTokenizer\n",
    "from pyspark.ml.functions import *\n",
    "from pyspark.sql.types import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8dd282ae-a7e8-4a6b-8e2f-95cdedcbadf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|                 exm|\n",
      "+---+--------------------+\n",
      "|  0|Hi,I heard about ...|\n",
      "|  1|I wish could use ...|\n",
      "|  2|Logistic Regressi...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ex_df = spark.createDataFrame([(0,'Hi,I heard about spark'),(1,'I wish could use java classes for project'),\n",
    "                               (2,'Logistic Regression is base of ML')],['id','exm'])\n",
    "\n",
    "ex_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "308b769b-b485-439f-8758-6f996e257ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol='exm',outputCol='words')\n",
    "regextokenizer = RegexTokenizer(inputCol='exm',outputCol='words',pattern='\\\\W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3f08e016-1357-4c70-a769-d180b2a840ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "count_tokens = udf(lambda words : len(words),IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9a83470e-300a-4ff1-956c-0f7f089752c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| id|                 exm|               words|\n",
      "+---+--------------------+--------------------+\n",
      "|  0|Hi,I heard about ...|[hi,i, heard, abo...|\n",
      "|  1|I wish could use ...|[i, wish, could, ...|\n",
      "|  2|Logistic Regressi...|[logistic, regres...|\n",
      "+---+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized = tokenizer.transform(ex_df)\n",
    "tokenized.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "efbbb196-0e60-40c0-ba78-11125292e293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+------+\n",
      "| id|                 exm|               words|tokens|\n",
      "+---+--------------------+--------------------+------+\n",
      "|  0|Hi,I heard about ...|[hi,i, heard, abo...|     4|\n",
      "|  1|I wish could use ...|[i, wish, could, ...|     8|\n",
      "|  2|Logistic Regressi...|[logistic, regres...|     6|\n",
      "+---+--------------------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized.withColumn('tokens',count_tokens(col('words'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "37e2493d-183c-41a6-9b04-a9cdfb9dfe96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+------+\n",
      "| id|                 exm|               words|tokens|\n",
      "+---+--------------------+--------------------+------+\n",
      "|  0|Hi,I heard about ...|[hi, i, heard, ab...|     5|\n",
      "|  1|I wish could use ...|[i, wish, could, ...|     8|\n",
      "|  2|Logistic Regressi...|[logistic, regres...|     6|\n",
      "+---+--------------------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rgtokenized = regextokenizer.transform(ex_df)\n",
    "rgtokenized.withColumn('tokens',count_tokens(col('words'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dd5a9718-c33d-4426-ae82-6de544f7b744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords removal\n",
    "from pyspark.ml.feature import StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b9df9c10-c72c-499f-8a41-29ecd0acada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords are used to remove the articles i the and etc\n",
    "\n",
    "remover = StopWordsRemover(inputCol='exm1',outputCol='filtered')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a9d387ee-d5be-45a3-ba95-6c22b13b80ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1 = spark.createDataFrame([(1,['I','girl','and ','On','The','floor','And','saw','An','path']),(2,['An','universe' ,'made','Of','The','particle'])],['id','exm1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eabb6ee4-bb76-43c4-ae5a-8a02fd438659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|                exm1|\n",
      "+---+--------------------+\n",
      "|  1|[I, girl, and , O...|\n",
      "|  2|[An, universe, ma...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ex1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "aa5635cd-97e1-4e2f-a14e-94b28e1f9dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| id|                exm1|            filtered|\n",
      "+---+--------------------+--------------------+\n",
      "|  1|[I, girl, and , O...|[girl, and , floo...|\n",
      "|  2|[An, universe, ma...|[universe, made, ...|\n",
      "+---+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remover.transform(ex1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "93066eae-91cf-444d-b81c-bff6406c54c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import NGram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "03aa5f8f-64a1-4330-a5e2-42d69e8f1bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = NGram(n=2,inputCol='exm1',outputCol='grams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b76ceaab-a95e-45de-a201-d503b03902a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| id|                exm1|               grams|\n",
      "+---+--------------------+--------------------+\n",
      "|  1|[I, girl, and , O...|[I girl, girl and...|\n",
      "|  2|[An, universe, ma...|[An universe, uni...|\n",
      "+---+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngram.transform(ex1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2a3f6e20-f144-444c-b07f-21e59e77af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9bb814ac-c341-4459-8005-38d397eff22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| id|                 exm|               words|\n",
      "+---+--------------------+--------------------+\n",
      "|  0|Hi,I heard about ...|[hi,i, heard, abo...|\n",
      "|  1|I wish could use ...|[i, wish, could, ...|\n",
      "|  2|Logistic Regressi...|[logistic, regres...|\n",
      "+---+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# implementing Tfidf and hashingtf\n",
    "\n",
    "words_data = tokenizer.transform(ex_df)\n",
    "\n",
    "words_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8b656176-5e33-4738-bdf0-cbb058462bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingtf = HashingTF(inputCol='words',outputCol='rawFeatures')\n",
    "\n",
    "featured_data = hashingtf.transform(words_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c4fa96aa-13ce-4ab6-b756-768532466e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+\n",
      "| id|                 exm|               words|         rawFeatures|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "|  0|Hi,I heard about ...|[hi,i, heard, abo...|(262144,[18700,48...|\n",
      "|  1|I wish could use ...|[i, wish, could, ...|(262144,[19036,20...|\n",
      "|  2|Logistic Regressi...|[logistic, regres...|(262144,[46243,10...|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featured_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f10f1b0d-3dc5-43a7-95a3-99dfcb3eef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol='rawFeatures',outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f1c360ed-c386-4f6c-8e75-5079682de8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "idfmodel = idf.fit(featured_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f06ca5ea-d841-4b41-b66b-31e61c4d7b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled = idfmodel.transform(featured_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "10509b7e-35c2-4cb2-aea7-c2675605a157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/12 13:07:35 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "24/01/12 13:07:35 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|id |features                                                                                                                                                                                                              |\n",
      "+---+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0  |(262144,[18700,48163,66273,173558],[0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453])                                                                                                     |\n",
      "|1  |(262144,[19036,20719,50886,55551,58672,98717,106776,109547],[0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453])|\n",
      "|2  |(262144,[46243,106841,190884,195421,219087,233470],[0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453])                                               |\n",
      "+---+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/12 13:07:35 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n"
     ]
    }
   ],
   "source": [
    "rescaled.select('id','features').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1e46e49b-f3db-48aa-ae6f-fcbeec9bf669",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(inputCol='exm1',outputCol='features',vocabSize=3,minDF=2.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "77f1327b-ecb0-4ec8-a075-a79391524f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvm = cv.fit(ex1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8dbf5f2a-b76e-46fd-baeb-fec0e74f4e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-------------------+\n",
      "| id|                exm1|           features|\n",
      "+---+--------------------+-------------------+\n",
      "|  1|[I, girl, and , O...|(2,[0,1],[1.0,1.0])|\n",
      "|  2|[An, universe, ma...|(2,[0,1],[1.0,1.0])|\n",
      "+---+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = cvm.transform(ex1)\n",
    "res.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
